{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:46:59.121612Z",
     "start_time": "2021-06-24T02:46:54.479443Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scipy.stats import expon, uniform\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import random\n",
    "import collections\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow_probability.python.mcmc.transformed_kernel import (\n",
    "    make_transform_fn, make_transformed_log_prob)\n",
    "\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "dtype = tf.float32\n",
    "tfde = tfp.experimental.distributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control versions of TF and TFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T05:29:29.324448Z",
     "start_time": "2021-06-24T05:29:29.317576Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot(x):\n",
    "    fig = plt.figure(figsize=(6, 2))\n",
    "    sns.distplot(x, hist = False, kde = True,\n",
    "                kde_kws = {'shade': True, 'linewidth': 1}, color = 'c')\n",
    "    plt.axvline(x = statistics.median(x))\n",
    "    print(statistics.median(x))\n",
    "    plt.xlim(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:47:00.753922Z",
     "start_time": "2021-06-24T02:47:00.745963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0-dev20210616'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:47:02.233608Z",
     "start_time": "2021-06-24T02:47:02.229638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.13.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example model: Normal distirbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('sigma', ()), ('mu', ()), ('x', ('mu', 'sigma')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=2.1403925>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=-6.5772223>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=-7.2311325>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example model \n",
    "\n",
    "mu = 12\n",
    "sigma = 2.2\n",
    "data = np.random.normal(mu, sigma, size=1000)\n",
    "\n",
    "# Defining the model\n",
    "model = tfd.JointDistributionSequential([\n",
    "    # sigma_prior\n",
    "    tfd.Exponential(1, name='sigma'),\n",
    "\n",
    "    # mu_prior\n",
    "    tfd.Normal(loc=0, scale=10, name='mu'),\n",
    "\n",
    "    # likelihood\n",
    "    lambda mu, sigma: tfd.Normal(loc=mu, scale=sigma)\n",
    "])\n",
    "\n",
    "#simple normal example\n",
    "print(model.resolve_graph())\n",
    "joint_log_prob = lambda *x: model.log_prob(x + (data,))\n",
    "model.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real model: Simplified ASE model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T04:56:01.460152Z",
     "start_time": "2021-06-24T04:56:01.433353Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('log2_theta', ()), ('x', ('log2_theta',)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=0.069106385>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=241.0>]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Simulated data from STANINPUTS\n",
    "depth = 5\n",
    "theta = 2\n",
    "data = []\n",
    "with open(\"JABS/STANINPUTS/data_N1000_H1_D{}_T2_F0.txt\".format(depth),\"rt\") as IN:\n",
    "        for line in IN:\n",
    "            fields=line.rstrip().split()\n",
    "            fields = [float(i) for i in fields]\n",
    "            #fields = fields[2:3]\n",
    "            data.append(fields[2:3])\n",
    "data = sum(data,[])\n",
    "\n",
    "#### Simulated data from np\n",
    "\n",
    "data = np.random.binomial(depth*100,theta/(1+theta), 1000)\n",
    "\n",
    "\n",
    "#### Defining the model\n",
    "sigma = 0.5\n",
    "model = tfd.JointDistributionSequential([\n",
    "    # log2_theta prior\n",
    "    tfd.Normal(loc=0, scale=sigma, name='log2_theta'),\n",
    "\n",
    "    # likelihood\n",
    "    lambda log2_theta: tfd.Binomial(depth*100,probs = (pow(2,log2_theta)/(1+ pow(2,log2_theta)) )) \n",
    "])\n",
    "\n",
    "\n",
    "#simple normal example\n",
    "print(model.resolve_graph())\n",
    "joint_log_prob = lambda *x: model.log_prob(x + (data,))\n",
    "model.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel Example\n",
    "https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Multilevel_Modeling_Primer.ipynb#scrollTo=-bPcpgMsIykz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real model: BIRD model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIRD STAN code\n",
    "data {\n",
    "   int<lower=1> N_VARIANTS;             // number of variants in the model\n",
    "   real<lower=0,upper=1> v[N_VARIANTS]; // alt allele freq in VCF file\n",
    "   int<lower=1> N_DNA;                  // number of DNA replicates\n",
    "   int<lower=0> a[N_VARIANTS,N_DNA];   // DNA alt read counts\n",
    "   int<lower=0> b[N_VARIANTS,N_DNA];   // DNA ref read counts\n",
    "   int<lower=1> N_RNA;                  // number of RNA replicates\n",
    "   int<lower=0> k[N_VARIANTS,N_RNA];   // RNA alt read counts\n",
    "   int<lower=0> m[N_VARIANTS,N_RNA];   // RNA ref read counts\n",
    "}\n",
    "\n",
    "parameters {\n",
    "   real<lower=0,upper=1> p[N_VARIANTS]; // alt allele freq in DNA\n",
    "   real<lower=0,upper=1> qi[N_VARIANTS,N_RNA]; // alt freqs in RNA\n",
    "   real<lower=0> theta[N_VARIANTS];\n",
    "   real<lower=2> c1; // concentration parameter of beta prior for qi\n",
    "   real<lower=2> c2; // concentration parameter of beta prior for p\n",
    "   real<lower=0> s; // std.dev. parameter of lognormal prior for theta\n",
    "}\n",
    "\n",
    "transformed parameters { // ORDER MATTERS!\n",
    "   real<lower=0,upper=1> q[N_VARIANTS]; // alt allele freq in RNA\n",
    "   for(j in 1:N_VARIANTS)\n",
    "      q[j]=theta[j]*p[j]/(1.0-p[j]+theta[j]*p[j]);\n",
    "}\n",
    "\n",
    "model {\n",
    "   // Parameters\n",
    "   c1 ~ gamma(1.1, 0.005);\n",
    "   c2 ~ gamma(1.1, 0.005);\n",
    "   s ~ gammaModeSD(1,1);\n",
    "\n",
    "   for(j in 1:N_VARIANTS) {\n",
    "      p[j] ~ betaModeConc(v[j],c2);\n",
    "      #\n",
    "      log(theta[j])/s ~ normal(0,1); // theta~lognormal(0,s)\n",
    "      target+=-log(theta[j])-log(s); // Jacobian\n",
    "      for(i in 1:N_RNA)\n",
    "         qi[j,i] ~ betaModeConc(q[j],c1);\n",
    "      for(i in 1:N_DNA)\n",
    "         a[j,i] ~ binomial(a[j,i]+b[j,i],p[j]);\n",
    "      for(i in 1:N_RNA)\n",
    "         k[j,i] ~ binomial(k[j,i]+m[j,i],qi[j,i]);\n",
    "   }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T06:23:30.597803Z",
     "start_time": "2021-06-24T06:23:30.592880Z"
    }
   },
   "outputs": [],
   "source": [
    "# BIRD Function \n",
    "def GammaModeSD(mode, sd, name = None):\n",
    "    r=(mode+np.sqrt(mode**2+4*(sd**2)))/(2*(sd**2))\n",
    "    s=1 + (mode*r)\n",
    "    return tfd.Gamma(concentration= tf.cast(r,tf.float32), rate = tf.cast(s,tf.float32), name= name)\n",
    "\n",
    "def BetaModeConc(mode,c, name = None):\n",
    "    c1 = mode*(c-2)+1\n",
    "    c2 = (1-mode)*(c-1)+1\n",
    "    return tfd.Beta(concentration1 = tf.cast(c1,tf.float32), concentration0=tf.cast(c2,tf.float32), name = name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T06:31:29.677212Z",
     "start_time": "2021-06-24T06:31:29.597785Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  c1=<tf.Tensor: shape=(), dtype=float32, numpy=208.56717>,\n",
       "  c2=<tf.Tensor: shape=(), dtype=float32, numpy=119.7016>,\n",
       "  s=<tf.Tensor: shape=(), dtype=float32, numpy=1.0168474>,\n",
       "  theta=<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "    array([3.0010018 , 0.15060464, 0.8979827 , 4.072646  , 2.126497  ,\n",
       "           1.1117243 , 0.20129718, 1.3587592 , 1.0721883 , 0.4174209 ],\n",
       "          dtype=float32)>,\n",
       "  p=<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "    array([0.10762128, 0.09902164, 0.09412014, 0.12293765, 0.09795275,\n",
       "           0.09797671, 0.08842909, 0.11935028, 0.1315391 , 0.08076626],\n",
       "          dtype=float32)>,\n",
       "  qi=<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "    array([[0.23839992, 0.2900599 , 0.3372831 , 0.25857127, 0.23782828,\n",
       "            0.25681162, 0.28601247, 0.24657485, 0.30077696, 0.28241098],\n",
       "           [0.02376759, 0.06525993, 0.04023969, 0.01561907, 0.01232368,\n",
       "            0.00938773, 0.01473299, 0.03366718, 0.04613873, 0.02386975],\n",
       "           [0.08110955, 0.13673818, 0.09149945, 0.07759854, 0.13364586,\n",
       "            0.07282746, 0.09832302, 0.11619961, 0.07951665, 0.07668033],\n",
       "           [0.33647144, 0.37137252, 0.3835762 , 0.34405255, 0.38198942,\n",
       "            0.331049  , 0.3076756 , 0.37030095, 0.35600674, 0.33709922],\n",
       "           [0.23970824, 0.23333761, 0.18935248, 0.20025063, 0.15539607,\n",
       "            0.21727264, 0.14985213, 0.12719133, 0.25295877, 0.1112254 ],\n",
       "           [0.1274412 , 0.10369173, 0.07449853, 0.11917037, 0.11993158,\n",
       "            0.10480401, 0.10779026, 0.14189294, 0.09520063, 0.13095218],\n",
       "           [0.05542633, 0.04149592, 0.0170505 , 0.01455164, 0.00879321,\n",
       "            0.04564175, 0.04019883, 0.01907685, 0.0209896 , 0.01825914],\n",
       "           [0.13559082, 0.11660624, 0.15009096, 0.11235353, 0.15974438,\n",
       "            0.18307054, 0.19664264, 0.08721372, 0.10219696, 0.17727157],\n",
       "           [0.08562818, 0.1262675 , 0.10672748, 0.18921003, 0.13939768,\n",
       "            0.13533872, 0.1379314 , 0.16894329, 0.16959977, 0.12355328],\n",
       "           [0.06062487, 0.04142594, 0.04027906, 0.04904568, 0.03697008,\n",
       "            0.06043473, 0.02381435, 0.03069568, 0.0610415 , 0.04481819]],\n",
       "          dtype=float32)>,\n",
       "  k=<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
       "    array([[15., 13., 21., 18., 13., 15., 20., 16., 17., 17.],\n",
       "           [12.,  9., 13., 22., 13., 13., 15., 16., 14., 10.],\n",
       "           [15., 17., 16., 13., 15., 18., 13., 16., 19., 20.],\n",
       "           [19., 21., 16., 19., 21., 16., 18., 17., 17., 19.],\n",
       "           [15., 16., 16., 19., 16., 16., 17., 13., 15., 17.],\n",
       "           [17., 16., 19., 15., 18., 14., 16., 18., 19., 16.],\n",
       "           [15., 13.,  9., 12., 19., 13., 19., 16., 17., 17.],\n",
       "           [13., 17., 16., 16., 16., 14., 18., 17., 19., 19.],\n",
       "           [15., 15., 17., 12., 16., 19., 18., 14., 17., 16.],\n",
       "           [14., 16., 10., 15., 12., 16., 18., 17., 10., 15.]], dtype=float32)>,\n",
       "  a=<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "    array([153., 157., 162., 163., 145., 164., 156., 161., 166., 152.],\n",
       "          dtype=float32)>\n",
       ")"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_V = 10\n",
    "N_DNA  =1\n",
    "N_RNA = 10\n",
    "V = 0.1\n",
    "D_DNA = 300\n",
    "D_RNA = 30\n",
    "DNA = [[150]*N_DNA]*N_V\n",
    "RNA = [[15]*N_RNA]*N_V\n",
    "\n",
    "\n",
    "@tfd.JointDistributionCoroutineAutoBatched\n",
    "def model():\n",
    "    ## c1 prior \n",
    "    c1 = yield tfd.Gamma(concentration = 1.1, rate = 0.005, name = \"c1\")\n",
    "    ## c2 prior\n",
    "    c2 = yield tfd.Gamma(concentration = 1.1, rate = 0.005, name = \"c2\")\n",
    "    ## s prior \n",
    "    s = yield GammaModeSD(1,1, name = \"s\")\n",
    "    ## theta prior \n",
    "    theta = yield tfd.Sample(tfd.LogNormal(0,s,name = \"theta\"), sample_shape=[N_V], name = \"theta\")\n",
    "    ## p prior\n",
    "    p = yield tfd.Sample(BetaModeConc(0.1,c1,name = \"p\"), sample_shape= [N_V], name = \"p\")\n",
    "    ## tfp bug, need to cast tensor to float32\n",
    "    #theta = tf.cast(theta, tf.float32)\n",
    "    #p = tf.cast(p, tf.float32)\n",
    "    ## q formula\n",
    "    q = (theta*p)/(1-p+theta*p)\n",
    "    ## qi prior \n",
    "    qi = yield tfd.Sample(BetaModeConc(q, c2, name = \"qi\"),sample_shape=[N_RNA], name = \"qi\")\n",
    "    ## qi likelihood \n",
    "    yield tfd.Binomial(tf.cast(D_RNA,tf.float32),qi, name = \"k\")\n",
    "    # p likelihood\n",
    "    yield tfd.Binomial(tf.cast(D_DNA,tf.float32),p, name = \"a\")    \n",
    "\n",
    "\n",
    "target_model = model.experimental_pin(a = DNA, k = RNA)\n",
    "\n",
    "model.sample()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T07:44:23.300103Z",
     "start_time": "2021-06-24T07:44:23.071721Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## single site BIRD\n",
    "N_V = 1\n",
    "N_DNA  =1\n",
    "N_RNA = 10\n",
    "V = 0.1\n",
    "D_DNA = 100\n",
    "D_RNA = 10\n",
    "DNA = [150]*N_DNA\n",
    "RNA = [15]*N_RNA\n",
    "\n",
    "@tfd.JointDistributionCoroutineAutoBatched\n",
    "def model():\n",
    "    ## c1 prior \n",
    "    c1 = yield tfd.Gamma(concentration = 1.1, rate = 0.005, name = \"c1\")\n",
    "    ## c2 prior\n",
    "    c2 = yield tfd.Gamma(concentration = 1.1, rate = 0.005, name = \"c2\")\n",
    "    ## s prior \n",
    "    s = yield GammaModeSD(1,1, name = \"s\")\n",
    "    ## theta prior \n",
    "    theta = yield tfd.LogNormal(0,s, name = \"theta\")\n",
    "    ## p prior\n",
    "    p = yield BetaModeConc(0.1,c1, name = \"p\")\n",
    "    ## tfp bug, need to cast tensor to float32\n",
    "    #theta = tf.cast(theta, tf.float32)\n",
    "    #p = tf.cast(p, tf.float32)\n",
    "    ## q formula\n",
    "    q = (theta*p)/(1-p+theta*p)\n",
    "    ## qi prior \n",
    "    qi = yield tfd.Sample(BetaModeConc(q, c2, name = \"qi\"),sample_shape=[N_RNA], name = \"qi\")\n",
    "    ## qi likelihood \n",
    "    yield tfd.Binomial(tf.cast(D_RNA,tf.float32),qi, name = \"k\")\n",
    "    # p likelihood\n",
    "    yield tfd.Binomial(tf.cast(D_DNA,tf.float32),p, name = \"a\")    \n",
    "\n",
    "\n",
    "target_model = model.experimental_pin(a = DNA, k = RNA)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T07:44:23.430947Z",
     "start_time": "2021-06-24T07:44:23.383182Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine the `event_shape` of the posterior, and calculate the size of each\n",
    "# `event_shape` component. These determine the sizes of the components of the\n",
    "# underlying standard Normal distribution, and the dimensions of the blocks in\n",
    "# the blockwise matrix transformation.\n",
    "event_shape = target_model.event_shape_tensor()\n",
    "flat_event_shape = tf.nest.flatten(event_shape)\n",
    "flat_event_size = tf.nest.map_structure(tf.reduce_prod, flat_event_shape)\n",
    "\n",
    "# The `event_space_bijector` maps unconstrained values (in R^n) to the support\n",
    "# of the prior -- we'll need this at the end to constrain Multivariate Normal\n",
    "# samples to the prior's support.\n",
    "event_space_bijector = target_model.experimental_default_event_space_bijector()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T07:44:59.322076Z",
     "start_time": "2021-06-24T07:44:32.467507Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed Tensor(\"monte_carlo_variational_loss/expectation/JointDistributionCoroutineAutoBatched/unnormalized_log_prob/Const:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n",
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed Tensor(\"monte_carlo_variational_loss/expectation/JointDistributionCoroutineAutoBatched/unnormalized_log_prob/Const:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n",
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed [0 0], implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean-field surrogate posterior ELBO: -inf\n"
     ]
    }
   ],
   "source": [
    "# A block-diagonal linear operator, in which each block is a diagonal operator,\n",
    "# transforms the standard Normal base distribution to produce a mean-field\n",
    "# surrogate posterior.\n",
    "operators = (tf.linalg.LinearOperatorDiag,\n",
    "             tf.linalg.LinearOperatorDiag,\n",
    "             tf.linalg.LinearOperatorDiag,\n",
    "             tf.linalg.LinearOperatorDiag,\n",
    "             tf.linalg.LinearOperatorDiag,\n",
    "             tf.linalg.LinearOperatorDiag)\n",
    "block_diag_linop = (\n",
    "    tfp.experimental.vi.util.build_trainable_linear_operator_block(\n",
    "        operators, flat_event_size))\n",
    "mean_field_scale = tfb.ScaleMatvecLinearOperatorBlock(block_diag_linop)\n",
    "\n",
    "mean_field_loc = tfb.JointMap(\n",
    "    tf.nest.map_structure(\n",
    "        lambda s: tfb.Shift(\n",
    "            tf.Variable(tf.random.uniform(\n",
    "                (s,), minval=-2., maxval=2., dtype=tf.float32))),\n",
    "        flat_event_size))\n",
    "\n",
    "mean_field_surrogate_posterior = tfd.TransformedDistribution(\n",
    "    base_standard_dist,\n",
    "    bijector = tfb.Chain(  # Note that the chained bijectors are applied in reverse order\n",
    "        [\n",
    "         event_space_bijector,  # constrain the surrogate to the support of the prior\n",
    "         unflatten_bijector,  # pack the reshaped components into the `event_shape` structure of the posterior\n",
    "         reshape_bijector, # reshape the vector-valued components to match the shapes of the posterior components\n",
    "         mean_field_loc,   # allow for nonzero mean\n",
    "         mean_field_scale  # apply the block matrix transformation to the standard Normal distribution\n",
    "         ]))\n",
    "\n",
    "\n",
    "optimizer=tf.optimizers.Adam(learning_rate=1e-2)\n",
    "@tf.function(jit_compile=True)\n",
    "def fit_vi():\n",
    "    return tfp.vi.fit_surrogate_posterior(\n",
    "        target_model.unnormalized_log_prob,\n",
    "        mean_field_surrogate_posterior,\n",
    "        optimizer=optimizer,\n",
    "        num_steps=5000,\n",
    "        sample_size=1)\n",
    "mean_field_loss = fit_vi()\n",
    "\n",
    "mean_field_samples = mean_field_surrogate_posterior.sample(1000)\n",
    "mean_field_final_elbo = tf.reduce_mean(\n",
    "    target_model.unnormalized_log_prob(*mean_field_samples)\n",
    "\n",
    "    - mean_field_surrogate_posterior.log_prob(mean_field_samples))\n",
    "print('Mean-field surrogate posterior ELBO: {}'.format(mean_field_final_elbo))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T07:45:03.290637Z",
     "start_time": "2021-06-24T07:45:03.149699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mean_field_loss)\n",
    "plt.xlabel('Training step')\n",
    "_ = plt.ylabel('Loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T07:45:04.140471Z",
     "start_time": "2021-06-24T07:45:03.989630Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0051374435424805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(np.array(mean_field_samples[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T07:10:52.380339Z",
     "start_time": "2021-06-24T07:10:52.187025Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Differences between `event_ndims` and `min_event_ndims must be equal for all elements of the structured input. Saw event_ndims=[1, 1, 1, 2, 2, 2], min_event_ndims=[1, 1, 1, 1, 1, 1].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-364-1a147cc204ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m iaf_surrogate_posterior = tfd.TransformedDistribution(\n\u001b[1;32m     24\u001b[0m     \u001b[0mbase_distribution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     bijector=tfb.Chain([\n\u001b[0m\u001b[1;32m     26\u001b[0m          \u001b[0mevent_space_bijector\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# constrain the surrogate to the support of the prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m          \u001b[0munflatten_bijector\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pack the reshaped components into the `event_shape` structure of the prior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/bijectors/chain.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, bijectors, validate_args, validate_event_size, parameters, name)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m       super(Chain, self).__init__(\n\u001b[0m\u001b[1;32m    128\u001b[0m           \u001b[0mbijectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbijectors\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m           \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/bijectors/composition.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, bijectors, name, parameters, forward_min_event_ndims, inverse_min_event_ndims, validate_event_size, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mforward_min_event_ndims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0minferred\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minferred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_min_event_ndims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             self._walk_inverse(\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0m_update_forward_min_event_ndims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 tf.nest.map_structure(lambda x: None, forward_min_event_ndims)))\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/bijectors/chain.py\u001b[0m in \u001b[0;36m_walk_inverse\u001b[0;34m(self, step_fn, y, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;34m\"\"\"Applies `transform_fn` to `y` sequentially over nested bijectors.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbij\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bijectors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbij\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m  \u001b[0;31m# Now `x`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/bijectors/composition.py\u001b[0m in \u001b[0;36m_update_forward_min_event_ndims\u001b[0;34m(bij, downstream_quantities, get_forward_min_event_ndims, get_inverse_min_event_ndims, inverse_event_ndims_fn)\u001b[0m\n\u001b[1;32m    686\u001b[0m       \u001b[0;31m# Pull the desired output ndims back through the bijector, to get\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;31m# the ndims of a valid *input*.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m       forward_min_event_ndims=inverse_event_ndims_fn(\n\u001b[0m\u001b[1;32m    689\u001b[0m           bij, valid_inverse_min_event_ndims),\n\u001b[1;32m    690\u001b[0m       parts_interact=(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/bijectors/composition.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(b, nd)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0mget_forward_min_event_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_min_event_ndims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0mget_inverse_min_event_ndims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_min_event_ndims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m     inverse_event_ndims_fn=lambda b, nd: b.inverse_event_ndims(nd)):\n\u001b[0m\u001b[1;32m    620\u001b[0m   \"\"\"Step backwards through the graph to infer `forward_min_event_ndims`.\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36minverse_event_ndims\u001b[0;34m(self, event_ndims, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0minverse_event_ndims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ndims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;34m\"\"\"Returns the number of event dimensions produced by `inverse`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m     ldj_reduce_ndims = ldj_reduction_ndims(\n\u001b[0m\u001b[1;32m   1504\u001b[0m         \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoerce_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_min_event_ndims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_ndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         self._inverse_min_event_ndims)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/bijectors/bijector.py\u001b[0m in \u001b[0;36mldj_reduction_ndims\u001b[0;34m(event_ndims, min_event_ndims, validate_args, name)\u001b[0m\n\u001b[1;32m   1736\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdifferences_all_static\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_differences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1738\u001b[0;31m           raise ValueError(\n\u001b[0m\u001b[1;32m   1739\u001b[0m               ('Differences between `event_ndims` and `min_event_ndims must be '\n\u001b[1;32m   1740\u001b[0m                \u001b[0;34m'equal for all elements of the structured input. Saw '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Differences between `event_ndims` and `min_event_ndims must be equal for all elements of the structured input. Saw event_ndims=[1, 1, 1, 2, 2, 2], min_event_ndims=[1, 1, 1, 1, 1, 1]."
     ]
    }
   ],
   "source": [
    "# Build a standard Normal with a vector `event_shape`, with length equal to the\n",
    "# total number of degrees of freedom in the posterior.\n",
    "base_distribution = tfd.Sample(\n",
    "    tfd.Normal(0., 1.), sample_shape=[tf.reduce_sum(flat_event_size)])\n",
    "\n",
    "# Apply an IAF to the base distribution.\n",
    "num_iafs = 6\n",
    "iaf_bijectors = [\n",
    "    tfb.Invert(tfb.MaskedAutoregressiveFlow(\n",
    "        shift_and_log_scale_fn=tfb.AutoregressiveNetwork(\n",
    "            params=2, hidden_units=[256, 256], activation='relu')))\n",
    "    for _ in range(num_iafs)\n",
    "]\n",
    "\n",
    "# Split the base distribution's `event_shape` into components that are equal\n",
    "# in size to the prior's components.\n",
    "split = tfb.Split(flat_event_size)\n",
    "\n",
    "# Chain these bijectors and apply them to the standard Normal base distribution\n",
    "# to build the surrogate posterior. `event_space_bijector`,\n",
    "# `unflatten_bijector`, and `reshape_bijector` are the same as in the\n",
    "# multivariate Normal surrogate posterior.\n",
    "iaf_surrogate_posterior = tfd.TransformedDistribution(\n",
    "    base_distribution,\n",
    "    bijector=tfb.Chain([\n",
    "         event_space_bijector,  # constrain the surrogate to the support of the prior\n",
    "         unflatten_bijector,  # pack the reshaped components into the `event_shape` structure of the prior\n",
    "         reshape_bijector,  # reshape the vector-valued components to match the shapes of the prior components\n",
    "         split] +  # Split the samples into components of the same size as the prior components\n",
    "         iaf_bijectors  # Apply a flow model to the Tensor-valued standard Normal distribution\n",
    "         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T07:12:03.171489Z",
     "start_time": "2021-06-24T07:11:00.710550Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed Tensor(\"monte_carlo_variational_loss/expectation/JointDistributionCoroutineAutoBatched/unnormalized_log_prob/Const:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n",
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed Tensor(\"monte_carlo_variational_loss/expectation/JointDistributionCoroutineAutoBatched/unnormalized_log_prob/Const:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n",
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed [0 0], implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incompatible shapes for broadcasting: (1000,) and (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-365-d91c5354a222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0miaf_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miaf_surrogate_posterior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m iaf_final_elbo = tf.reduce_mean(\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnormalized_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miaf_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     - iaf_surrogate_posterior.log_prob(iaf_samples))\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/experimental/distributions/joint_distribution_pinned.py\u001b[0m in \u001b[0;36munnormalized_log_prob\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \"\"\"\n\u001b[1;32m    576\u001b[0m     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_pins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnormalized_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_pins\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m   @docstring_util.expand_docstring(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\u001b[0m in \u001b[0;36munnormalized_log_prob\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \"\"\"\n\u001b[1;32m    666\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unnormalized_log_prob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return self._call_unnormalized_log_prob(\n\u001b[0m\u001b[1;32m    668\u001b[0m         self._resolve_value(*args, **kwargs), name=name)\n\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/distribution.py\u001b[0m in \u001b[0;36m_call_unnormalized_log_prob\u001b[0;34m(self, value, name, **kwargs)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_and_control_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_unnormalized_log_prob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unnormalized_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_unnormalized_prob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unnormalized_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution_sample_path_mixin.py\u001b[0m in \u001b[0;36m_unnormalized_log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    182\u001b[0m           'unnormalized_log_prob', tfp_math.reduce_kahan_sum, value)\n\u001b[1;32m    183\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     xs = self._map_and_reduce_measure_over_dists(\n\u001b[0m\u001b[1;32m    185\u001b[0m         'unnormalized_log_prob', tf.reduce_sum, value)\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution_sample_path_mixin.py\u001b[0m in \u001b[0;36m_map_and_reduce_measure_over_dists\u001b[0;34m(self, attr, reduce_fn, value)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_map_and_reduce_measure_over_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m\"\"\"Reduces all non-batch dimensions of the provided measure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_measure_over_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     num_trailing_batch_dims_treated_as_event = [\n\u001b[1;32m    130\u001b[0m         prefer_static.rank_from_shape(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\u001b[0m in \u001b[0;36m_map_measure_over_dists\u001b[0;34m(self, attr, value)\u001b[0m\n\u001b[1;32m    538\u001b[0m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     return self._call_execute_model(\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0msample_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution_vmap_mixin.py\u001b[0m in \u001b[0;36m_call_execute_model\u001b[0;34m(self, sample_shape, seed, value, sample_and_trace_fn)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# not currently supporting keyword args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         lambda v, seed: batch_execute_model(v, seed), sample_shape)  # pylint: disable=unnecessary-lambda\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvectorized_execute_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_default_event_space_bijector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py\u001b[0m in \u001b[0;36miid_sample_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstatic_n\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mdraws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpfor_loop_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mdraws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_for\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpfor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfor_loop_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py\u001b[0m in \u001b[0;36mpfor_loop_body\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpfor_loop_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iid_sample_fn_stateless_body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstatic_n\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution_vmap_mixin.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(v, seed)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# Redefine the polymorphic fn to hack around `make_rank_polymorphic`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# not currently supporting keyword args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         lambda v, seed: batch_execute_model(v, seed), sample_shape)  # pylint: disable=unnecessary-lambda\n\u001b[0m\u001b[1;32m    153\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvectorized_execute_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py\u001b[0m in \u001b[0;36mvectorized_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    303\u001b[0m               for (arg_shape, nd) in zip(vectorized_arg_shapes, batch_ndims)])\n\u001b[1;32m    304\u001b[0m         broadcast_batch_shape = (\n\u001b[0;32m--> 305\u001b[0;31m             functools.reduce(ps.broadcast_shape, batch_shapes, []))\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0;31m# Flatten all of the batch dimensions into one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/prefer_static.py\u001b[0m in \u001b[0;36mbroadcast_shape\u001b[0;34m(x_shape, y_shape)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_dynamic_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m   return tf.broadcast_static_shape(\n\u001b[0m\u001b[1;32m    225\u001b[0m       tf.TensorShape(x_shape_static), tf.TensorShape(y_shape_static))\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mbroadcast_static_shape\u001b[0;34m(shape_x, shape_y)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtwo\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0mcan\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mbroadcasted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m   \"\"\"\n\u001b[0;32m--> 572\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcommon_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mbroadcast_shape\u001b[0;34m(shape_x, shape_y)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0mreturn_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreturn_dims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     raise ValueError(\"Incompatible shapes for broadcasting: %s and %s\"\n\u001b[0m\u001b[1;32m    107\u001b[0m                      % (shape_x, shape_y))\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible shapes for broadcasting: (1000,) and (10,)"
     ]
    }
   ],
   "source": [
    "optimizer=tf.optimizers.Adam(learning_rate=1e-2)\n",
    "@tf.function(jit_compile=True)\n",
    "def fit_vi():\n",
    "  return tfp.vi.fit_surrogate_posterior(\n",
    "    target_model.unnormalized_log_prob,\n",
    "    iaf_surrogate_posterior,\n",
    "    optimizer=optimizer,\n",
    "    num_steps=5000,\n",
    "    sample_size=1\n",
    "    )\n",
    "iaf_loss = fit_vi()\n",
    "\n",
    "iaf_samples = iaf_surrogate_posterior.sample(1000)\n",
    "iaf_final_elbo = tf.reduce_mean(\n",
    "    target_model.unnormalized_log_prob(*iaf_samples)\n",
    "\n",
    "    - iaf_surrogate_posterior.log_prob(iaf_samples))\n",
    "print('IAF surrogate posterior ELBO: {}'.format(iaf_final_elbo))\n",
    "\n",
    "plt.plot(iaf_loss)\n",
    "plt.xlabel('Training step')\n",
    "_ = plt.ylabel('Loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T06:10:05.722744Z",
     "start_time": "2021-06-24T06:10:05.660662Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  c1=<tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
       "    array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          dtype=float32)>,\n",
       "  c2=<tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
       "    array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          dtype=float32)>,\n",
       "  s=<tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
       "    array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          dtype=float32)>,\n",
       "  theta=<tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
       "    array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          dtype=float32)>,\n",
       "  p=<tf.Tensor: shape=(1000,), dtype=float32, numpy=\n",
       "    array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "           nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "          dtype=float32)>,\n",
       "  qi=<tf.Tensor: shape=(1000, 10), dtype=float32, numpy=\n",
       "    array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "           [nan, nan, nan, ..., nan, nan, nan],\n",
       "           [nan, nan, nan, ..., nan, nan, nan],\n",
       "           ...,\n",
       "           [nan, nan, nan, ..., nan, nan, nan],\n",
       "           [nan, nan, nan, ..., nan, nan, nan],\n",
       "           [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)>\n",
       ")"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iaf_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T05:33:41.780634Z",
     "start_time": "2021-06-24T05:33:37.901632Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T05:33:41.796483Z",
     "start_time": "2021-06-24T05:33:41.782344Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T03:35:24.862220Z",
     "start_time": "2021-06-24T03:35:24.853414Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T03:50:41.550413Z",
     "start_time": "2021-06-24T03:50:41.512852Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T03:50:45.808742Z",
     "start_time": "2021-06-24T03:50:45.504605Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T03:51:02.590289Z",
     "start_time": "2021-06-24T03:51:02.384328Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T03:48:27.266787Z",
     "start_time": "2021-06-24T03:48:26.934541Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Joint distribution expected values for 8 components ['c1', 'c2', 's', 'theta', 'p', 'qi', 'k', 'a']; saw 9 (from args (<tf.Tensor 'monte_carlo_variational_loss/expectation/exp/forward/Exp:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_1:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_2:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_3:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_4:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_5:0' shape=(1000, 10) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/exp_1/forward/Exp:0' shape=(1000, 10) dtype=float32>) and kwargs {'a': [150], 'k': [15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-966fa60272e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0melbo_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0melbo_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_approximation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3057\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3059\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3060\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3456\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3289\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3291\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3292\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-966fa60272e2>\u001b[0m in \u001b[0;36mrun_approximation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_approximation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     elbo_loss = tfp.vi.fit_surrogate_posterior(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0msurrogate_posterior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeanfield_advi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/vi/optimization.py\u001b[0m in \u001b[0;36mfit_surrogate_posterior\u001b[0;34m(target_log_prob_fn, surrogate_posterior, optimizer, num_steps, convergence_criterion, trace_fn, variational_loss_fn, sample_size, trainable_variables, jit_compile, seed, name)\u001b[0m\n\u001b[1;32m    299\u001b[0m         seed=seed)\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   return tfp_math.minimize(complete_variational_loss_fn,\n\u001b[0m\u001b[1;32m    302\u001b[0m                            \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                            \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/math/minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(loss_fn, num_steps, optimizer, convergence_criterion, batch_convergence_reduce_fn, trainable_variables, trace_fn, return_full_length_trace, jit_compile, name)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         trainable_variables=trainable_variables)\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0minitial_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0mhas_converged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0minitial_convergence_criterion_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 759\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    760\u001b[0m             *args, **kwds))\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3057\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3058\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3059\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3060\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3455\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3456\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3457\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3289\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3291\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3292\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/math/minimize.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mwatched_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatched_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatched_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/vi/optimization.py\u001b[0m in \u001b[0;36mcomplete_variational_loss_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcomplete_variational_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     return variational_loss_fn(\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mtarget_log_prob_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0msurrogate_posterior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/vi/csiszar_divergence.py\u001b[0m in \u001b[0;36mmonte_carlo_variational_loss\u001b[0;34m(target_log_prob_fn, surrogate_posterior, sample_size, discrepancy_fn, use_reparameterization, seed, name)\u001b[0m\n\u001b[1;32m    960\u001b[0m                       'function.')\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m     return monte_carlo.expectation(\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdivergence_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/monte_carlo/expectation.py\u001b[0m in \u001b[0;36mexpectation\u001b[0;34m(f, samples, log_prob, use_reparameterization, axis, keepdims, name)\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`f` must be a callable function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_reparameterization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/vi/csiszar_divergence.py\u001b[0m in \u001b[0;36mdivergence_fn\u001b[0;34m(q_samples)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdivergence_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m       \u001b[0mtarget_log_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_log_prob_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m       return discrepancy_fn(\n\u001b[1;32m    936\u001b[0m           target_log_prob - surrogate_posterior.log_prob(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/nest_util.py\u001b[0m in \u001b[0;36mcall_fn\u001b[0;34m(fn, args)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mexpand_as_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0m_expand_as_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/mcmc/transformed_kernel.py\u001b[0m in \u001b[0;36mtransformed_log_prob_fn\u001b[0;34m(*state_parts)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menable_bijector_caching\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0mstate_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_parts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mtlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0mtlp_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefer_static\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mevent_ndims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_static\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtlp_rank\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstate_parts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-fc9d4aa6e6b8>\u001b[0m in \u001b[0;36mtarget_log_prob_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtarget_log_prob_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDNA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNA\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m '''\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \"\"\"\n\u001b[1;32m    632\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'log_prob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0;31m# Override the base method to capture *args and **kwargs, so we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\u001b[0m in \u001b[0;36m_resolve_value\u001b[0;34m(self, allow_partially_specified, *args, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_partially_specified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# In place update.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m     value, unmatched_kwargs = _resolve_value_from_args(\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/distributions/joint_distribution.py\u001b[0m in \u001b[0;36m_resolve_value_from_args\u001b[0;34m(args, kwargs, dtype, flat_names, model_flatten_fn, model_unflatten_fn)\u001b[0m\n\u001b[1;32m    993\u001b[0m   \u001b[0mnum_components_specified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munmatched_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnum_components_specified\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m     raise ValueError('Joint distribution expected values for {} components {}; '\n\u001b[0m\u001b[1;32m    996\u001b[0m                      'saw {} (from args {} and kwargs {}).'.format(\n\u001b[1;32m    997\u001b[0m                          \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Joint distribution expected values for 8 components ['c1', 'c2', 's', 'theta', 'p', 'qi', 'k', 'a']; saw 9 (from args (<tf.Tensor 'monte_carlo_variational_loss/expectation/exp/forward/Exp:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_1:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_2:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_3:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_4:0' shape=(1000,) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/Identity_5:0' shape=(1000, 10) dtype=float32>, <tf.Tensor 'monte_carlo_variational_loss/expectation/exp_1/forward/Exp:0' shape=(1000, 10) dtype=float32>) and kwargs {'a': [150], 'k': [15, 15, 15, 15, 15, 15, 15, 15, 15, 15]})."
     ]
    }
   ],
   "source": [
    "N = 1\n",
    "\n",
    "\n",
    "# Build Mean Field ADVI\n",
    "def build_mf_advi():\n",
    "    parameters = list(model.sample(1))\n",
    "    parameters.pop()\n",
    "    dists = []\n",
    "    for i, parameter in enumerate(parameters):\n",
    "        shape = parameter[0].shape\n",
    "        loc = tf.Variable(\n",
    "            tf.random.normal(shape, dtype=dtype),\n",
    "            name=f'meanfield_{i}_loc',\n",
    "            dtype=dtype\n",
    "        )\n",
    "        scale = tfp.util.TransformedVariable(\n",
    "            tf.fill(shape, value=tf.constant(0.02, dtype=dtype)),\n",
    "            tfb.Softplus(), # For positive values of scale\n",
    "            name=f'meanfield_{i}_scale'\n",
    "        )\n",
    "\n",
    "        approx_parameter = tfd.Normal(loc=loc, scale=scale)\n",
    "        dists.append(approx_parameter)\n",
    "    return tfd.JointDistributionSequential(dists)\n",
    "\n",
    "meanfield_advi = build_mf_advi()\n",
    "\n",
    "\n",
    "unconstraining_bijectors = [\n",
    "    tfb.Exp(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Exp()\n",
    "]\n",
    "\n",
    "posterior = make_transformed_log_prob(\n",
    "    target_log_prob_fn,\n",
    "    unconstraining_bijectors,\n",
    "    direction='forward',\n",
    "    enable_bijector_caching=False\n",
    ")\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=.1)\n",
    "\n",
    "@tf.function(autograph=False)\n",
    "def run_approximation():\n",
    "    elbo_loss = tfp.vi.fit_surrogate_posterior(\n",
    "        posterior,\n",
    "        surrogate_posterior=meanfield_advi,\n",
    "        optimizer=opt,\n",
    "        sample_size=1000,\n",
    "        num_steps=10000)\n",
    "    return elbo_loss\n",
    "\n",
    "elbo_loss = run_approximation()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Show ELBO curve through iteration\n",
    "# decrease the num_step according to the maximized ELBO plot\n",
    "plt.plot(elbo_loss, color='blue')\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"No of iterations\")\n",
    "plt.ylabel(\"Negative ELBO\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sigma': {'mu': 0.80642253, 'sd': -0.7141728}, 'mu': {'mu': 11.482767, 'sd': 1.7579931}}\n"
     ]
    }
   ],
   "source": [
    "graph_info = model.resolve_graph()\n",
    "approx_param = dict()\n",
    "free_param = meanfield_advi.trainable_variables\n",
    "for i, (rvname, param) in enumerate(graph_info[:-1]):\n",
    "    approx_param[rvname] = {\"mu\": free_param[i*2].numpy(),\n",
    "                            \"sd\": free_param[i*2+1].numpy()}\n",
    "    \n",
    "    \n",
    "#### approximate distribution parameter\n",
    "print(approx_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'log2_theta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2507588e749c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#### Recover theta & p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapprox_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log2_theta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log2_theta'"
     ]
    }
   ],
   "source": [
    "#### Recover theta & p\n",
    "theta = pow(2,np.exp(approx_param['log2_theta']['mu']))\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI Example\n",
    "https://www.tensorflow.org/probability/examples/Variational_Inference_and_Joint_Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:47:12.385519Z",
     "start_time": "2021-06-24T02:47:11.403925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the Radon dataset from `tensorflow_datasets` and filter to data from\n",
    "# Minnesota.\n",
    "dataset = tfds.as_numpy(\n",
    "    tfds.load('radon', split='train').filter(\n",
    "        lambda x: x['features']['state'] == 'MN').batch(10**9))\n",
    "\n",
    "# Dependent variable: Radon measurements by house.\n",
    "dataset = next(iter(dataset))\n",
    "radon_measurement = dataset['activity'].astype(np.float32)\n",
    "radon_measurement[radon_measurement <= 0.] = 0.1\n",
    "log_radon = np.log(radon_measurement)\n",
    "\n",
    "# Measured uranium concentrations in surrounding soil.\n",
    "uranium_measurement = dataset['features']['Uppm'].astype(np.float32)\n",
    "log_uranium = np.log(uranium_measurement)\n",
    "\n",
    "# County indicator.\n",
    "county_strings = dataset['features']['county'].astype('U13')\n",
    "unique_counties, county = np.unique(county_strings, return_inverse=True)\n",
    "county = county.astype(np.int32)\n",
    "num_counties = unique_counties.size\n",
    "\n",
    "# Floor on which the measurement was taken.\n",
    "floor_of_house = dataset['features']['floor'].astype(np.int32)\n",
    "\n",
    "# Average floor by county (contextual effect).\n",
    "county_mean_floor = []\n",
    "for i in range(num_counties):\n",
    "  county_mean_floor.append(floor_of_house[county == i].mean())\n",
    "county_mean_floor = np.array(county_mean_floor, dtype=log_radon.dtype)\n",
    "floor_by_county = county_mean_floor[county]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T03:19:57.644964Z",
     "start_time": "2021-06-24T03:19:57.575271Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructTuple(\n",
       "  uranium_weight=<tf.Tensor: shape=(), dtype=float32, numpy=0.96947145>,\n",
       "  county_floor_weight=<tf.Tensor: shape=(), dtype=float32, numpy=1.3516601>,\n",
       "  county_effect=<tf.Tensor: shape=(85,), dtype=float32, numpy=\n",
       "    array([-0.00891165,  0.51382756,  0.8887604 ,  1.0934656 ,  0.19063683,\n",
       "           -1.816842  ,  0.5573977 ,  0.43619174,  2.0679898 , -1.1282738 ,\n",
       "            1.2486008 , -1.2802231 , -0.16189353, -1.1235218 ,  1.7696934 ,\n",
       "            2.8856363 ,  0.05513172,  0.22909035,  1.543311  , -0.3902237 ,\n",
       "            1.3516245 ,  1.6085109 ,  0.43354324, -0.6679174 ,  0.14411198,\n",
       "            0.2123997 ,  0.41966498,  0.608672  ,  2.0688353 , -1.3939695 ,\n",
       "            1.1199465 ,  0.7059494 ,  0.33428255,  0.0595608 , -1.2506355 ,\n",
       "           -1.835246  ,  0.18616423,  1.6842955 , -0.17684548, -0.01327134,\n",
       "            0.52731216,  0.49517685, -0.12005948,  0.15049739,  0.43556112,\n",
       "            0.9437131 ,  0.3334335 ,  0.9390626 , -0.75552016,  1.1287478 ,\n",
       "            0.7798561 ,  0.1919702 ,  0.02494648,  1.234064  , -1.9833888 ,\n",
       "            0.15410747, -0.7495478 , -0.6573727 ,  0.23089726, -0.4834598 ,\n",
       "            0.32953617, -0.09370811,  0.30522493,  0.87971956, -0.00952477,\n",
       "           -0.25768077,  0.08262717,  0.02304848,  0.96394426, -2.1810536 ,\n",
       "           -1.0511245 , -0.13324268,  0.06132703, -0.2962708 ,  0.2734197 ,\n",
       "           -0.6023286 , -0.6357259 ,  0.7402906 , -0.5292223 , -1.4260477 ,\n",
       "            0.23416723, -1.249201  , -0.12897424,  0.3595788 ,  1.4858469 ],\n",
       "          dtype=float32)>,\n",
       "  log_radon=<tf.Tensor: shape=(919,), dtype=float32, numpy=\n",
       "    array([ 2.00680923e+00, -1.53015125e+00, -2.93183970e+00, -2.34576821e+00,\n",
       "           -2.96599793e+00,  2.49371469e-01,  1.50540078e+00,  4.82706845e-01,\n",
       "            1.08777797e+00,  1.38433790e+00,  8.31869125e-01,  2.82573605e+00,\n",
       "            2.49361217e-01,  2.27085114e+00, -1.62695587e+00, -4.60158157e+00,\n",
       "            1.24004841e-01, -1.19934344e+00,  1.89927638e-01,  4.63092655e-01,\n",
       "            5.41288733e-01,  9.57840383e-01,  1.95272923e-01, -1.32674158e-01,\n",
       "            3.92072231e-01, -2.01153576e-01, -2.31047535e+00, -4.18807358e-01,\n",
       "            2.81796193e+00,  3.39412951e+00,  1.70393717e+00, -7.05734372e-01,\n",
       "            3.56029868e-02, -1.07162285e+00, -2.85353708e+00,  1.43488705e+00,\n",
       "           -1.86319888e-01,  6.04159057e-01,  1.55769378e-01,  1.41853321e+00,\n",
       "            1.25117898e+00,  2.19343972e+00,  6.89863324e-01, -1.25290394e-01,\n",
       "            1.00656700e+00, -2.17384338e-01, -1.78043842e-02,  3.13958454e+00,\n",
       "            1.97396803e+00,  1.80891204e+00, -1.05278504e+00, -2.82061315e+00,\n",
       "           -1.06006956e+00,  2.37781763e+00, -2.14651632e+00,  2.77590573e-01,\n",
       "           -1.04600346e+00, -1.09174877e-01, -2.45839238e+00,  7.15075016e-01,\n",
       "           -2.05390501e+00,  3.43541086e-01, -1.02927852e+00,  6.28647655e-02,\n",
       "           -1.72917473e+00,  9.82934117e-01,  1.32698870e+00, -4.35266256e+00,\n",
       "           -3.58892083e+00,  6.39132977e-01, -8.89404774e-01,  6.75647855e-01,\n",
       "            4.17264581e-01, -9.59561467e-01,  1.62163842e+00,  1.22540402e+00,\n",
       "            2.04192638e+00,  1.39697301e+00,  2.17228031e+00, -6.68091416e-01,\n",
       "            2.35475361e-01, -2.85057724e-02,  9.45998609e-01, -1.86391020e+00,\n",
       "            8.57507139e-02,  8.03398430e-01, -2.57964444e+00, -1.96422637e-01,\n",
       "           -3.02833319e-01, -1.48297954e+00, -9.15291369e-01,  2.44181013e+00,\n",
       "           -9.05814409e-01, -1.43010378e+00,  1.49098301e+00,  2.58439183e-01,\n",
       "           -3.90263057e+00, -2.60682178e+00,  4.81323391e-01, -3.89363647e-01,\n",
       "           -2.11931229e+00,  1.60544187e-01, -3.92004752e+00,  2.06528139e+00,\n",
       "            1.58959937e+00, -1.69015574e+00, -1.69983888e+00, -2.30298591e+00,\n",
       "           -1.34931505e-03,  6.81413591e-01,  2.99513757e-01,  2.05487311e-01,\n",
       "            7.42149591e-01, -8.80099416e-01, -1.14896655e+00, -2.52445245e+00,\n",
       "            2.07495332e+00,  4.20337468e-02, -6.92671776e-01, -2.76497185e-01,\n",
       "           -5.69676280e-01,  7.79660702e-01,  1.16013527e+00, -3.60964108e+00,\n",
       "           -2.51509643e+00, -1.75060725e+00,  1.22595990e+00,  1.09805512e+00,\n",
       "           -2.90761590e-02,  3.01966071e-01,  2.88770604e+00, -1.40376282e+00,\n",
       "            1.43875301e+00, -1.64861655e+00, -4.03895235e+00, -1.26789021e+00,\n",
       "            8.10034394e-01,  3.21368754e-01, -7.67666399e-01,  2.24504066e+00,\n",
       "           -2.15170670e+00, -1.02542198e+00, -6.25372827e-01,  7.80708671e-01,\n",
       "            9.04997587e-01,  2.36072087e+00, -6.91660702e-01,  1.32886922e+00,\n",
       "           -1.80411625e+00,  3.00112545e-01,  8.05167794e-01,  1.37343109e-02,\n",
       "            1.13880050e+00, -3.31634092e+00,  2.53305006e+00, -6.87308550e-01,\n",
       "           -4.90755558e-01, -3.10880035e-01, -1.06071711e+00, -6.71991706e-01,\n",
       "            2.79743719e+00, -5.25991261e-01, -1.34265971e+00,  1.67254138e+00,\n",
       "           -1.43321872e-01, -6.39239430e-01,  2.05896258e+00,  1.43768644e+00,\n",
       "           -3.60183239e-01,  1.96514761e+00, -7.64903903e-01, -1.48515046e+00,\n",
       "            1.09818363e+00, -2.27432895e+00, -9.08621550e-02,  9.82287526e-01,\n",
       "            1.69061327e+00, -2.46560574e-02,  2.24757624e+00,  7.86755800e-01,\n",
       "           -1.82066846e+00, -4.08993292e+00,  2.71324682e+00, -2.04384375e+00,\n",
       "            1.59680033e+00,  1.06364512e+00, -9.57698941e-01, -5.25827169e-01,\n",
       "           -6.19405210e-01,  2.16225553e+00,  3.65808249e+00,  2.40306228e-01,\n",
       "           -1.92505431e+00,  1.49127972e+00,  3.43259573e+00,  3.09174418e-01,\n",
       "           -8.07914555e-01,  3.54116082e-01,  2.45465875e+00,  2.50201607e+00,\n",
       "           -1.11637771e+00, -1.90857542e+00,  9.07077789e-01,  7.46148348e-01,\n",
       "            1.66193938e+00,  9.67855453e-02,  3.97934079e+00, -1.48303342e+00,\n",
       "           -2.59691477e+00,  6.40033901e-01,  1.58759296e+00,  2.10012078e+00,\n",
       "            2.22138762e-01, -1.12873220e+00,  2.13449550e+00,  6.47669077e-01,\n",
       "           -1.32955098e+00, -1.50998116e-01,  2.23734784e+00, -2.44000292e+00,\n",
       "           -3.79151082e+00, -1.17208171e+00,  4.03725296e-01,  1.32693124e+00,\n",
       "           -4.82026637e-01, -2.05100250e+00,  3.78761959e+00,  1.71422505e+00,\n",
       "           -7.06542075e-01,  2.03961754e+00, -1.58751333e+00, -1.61633635e+00,\n",
       "            7.26569295e-02,  2.01145411e-02, -8.40826094e-01, -3.05762005e+00,\n",
       "            1.00050998e+00, -1.37952077e+00,  1.18187165e+00, -4.19928074e-01,\n",
       "           -2.48041868e+00, -1.34067631e+00, -4.73509669e-01,  2.04438806e+00,\n",
       "           -1.38984585e+00, -1.48101604e+00,  1.85760379e+00,  4.79972363e-03,\n",
       "            9.81588244e-01,  1.55908322e+00,  9.43287730e-01, -1.39598083e+00,\n",
       "           -3.96707028e-01, -1.96587229e+00,  4.68218505e-01,  2.00108528e+00,\n",
       "            2.48534298e+00, -1.95419979e+00,  1.34016144e+00, -2.66401076e+00,\n",
       "            2.69905925e-02,  7.31549203e-01,  2.42429304e+00,  5.40161967e-01,\n",
       "            1.15875220e+00, -1.71919465e+00,  2.86718845e+00, -1.37268758e+00,\n",
       "           -1.10002315e+00,  2.10360098e+00,  8.04060340e-01,  1.02275014e+00,\n",
       "            8.85273635e-01,  1.55927026e+00,  1.45232797e+00, -4.64780617e+00,\n",
       "            2.31906533e+00, -4.35068011e-01, -1.87101269e+00, -1.10751784e+00,\n",
       "           -1.95000148e+00,  1.11009383e+00,  1.60904932e+00,  1.42924154e+00,\n",
       "           -2.30419070e-01,  2.27667904e+00, -2.33257198e+00, -1.39084840e+00,\n",
       "            2.15796494e+00,  9.84542966e-01,  4.19915557e-01,  1.33309984e+00,\n",
       "            2.26373792e-01, -8.86207044e-01, -1.40026653e+00, -2.49914622e+00,\n",
       "           -4.27955568e-01,  2.13681746e+00, -9.63698149e-01, -2.66225815e+00,\n",
       "           -1.34337735e+00,  8.37101698e-01,  2.01619697e+00,  6.67994618e-01,\n",
       "           -4.07952428e-01, -4.32477427e+00,  7.83140063e-01,  7.74507642e-01,\n",
       "           -3.98592234e+00, -1.85176599e+00,  2.39225173e+00,  6.99412167e-01,\n",
       "            1.18787110e+00, -6.01399899e-01,  1.08280039e+00, -1.88658237e-02,\n",
       "            2.01970482e+00, -6.13220930e-01,  2.07117629e+00,  3.39645195e+00,\n",
       "            3.21667337e+00,  3.24494267e+00, -4.82658803e-01, -1.26552176e+00,\n",
       "           -1.42238200e-01, -1.06143653e-01, -2.89613724e+00,  3.76122952e+00,\n",
       "            9.34634566e-01,  5.73439121e-01,  2.57797241e+00, -9.41325426e-01,\n",
       "           -1.01356053e+00,  2.82711387e+00,  2.28702092e+00,  1.35191894e+00,\n",
       "           -1.40716028e+00,  8.69757593e-01, -1.89531446e+00,  1.26031721e+00,\n",
       "            1.79578567e+00,  1.78367987e-01,  1.52351427e+00,  1.36518979e+00,\n",
       "           -3.23042035e-01, -2.93744063e+00, -1.81980240e+00,  6.22891366e-01,\n",
       "            5.13983846e-01, -1.23216271e-01,  1.34428668e+00, -1.44053698e+00,\n",
       "           -1.27864265e+00, -5.65137565e-01,  1.02396220e-01, -2.60020757e+00,\n",
       "            2.26554489e+00, -1.04603922e+00, -1.33435202e+00, -5.24742842e-01,\n",
       "           -9.27870393e-01,  1.54868841e-01,  6.35969758e-01, -5.27833283e-01,\n",
       "           -4.52378464e+00,  6.74651980e-01, -1.90005529e+00, -2.40571886e-01,\n",
       "            8.01730216e-01, -2.06767917e+00,  6.25581563e-01,  9.23138261e-01,\n",
       "            2.38830256e+00, -9.19718325e-01, -3.24039966e-01, -2.92501450e-02,\n",
       "           -2.86686444e+00, -3.08843780e+00, -7.14715660e-01, -1.36424530e+00,\n",
       "            5.30362800e-02,  1.01053596e-01,  1.37612009e+00, -4.33881879e-01,\n",
       "            2.40958393e-01,  1.58604831e-01,  7.84433961e-01, -8.75646532e-01,\n",
       "            2.48788404e+00, -8.53986919e-01,  1.67949688e+00,  2.84164369e-01,\n",
       "           -2.35794216e-01, -9.77901459e-01, -4.15176570e-01,  3.90844107e-01,\n",
       "           -2.12987065e+00, -1.19861877e+00,  1.92945272e-01, -2.22094369e+00,\n",
       "            2.62242079e-01,  1.00479841e+00,  1.33107471e+00,  3.18499708e+00,\n",
       "           -3.32663774e-01, -9.24088657e-01,  2.35222244e+00,  1.60288525e+00,\n",
       "            8.07368338e-01, -1.16634154e+00, -1.89887285e+00,  1.69098592e+00,\n",
       "            1.15530300e+00,  1.05058581e-01,  1.01995754e+00, -5.33026397e-01,\n",
       "           -9.95013833e-01, -2.26444721e+00,  7.06429839e-01, -1.10904001e-01,\n",
       "           -1.43933821e+00, -2.82158709e+00, -1.66532469e+00,  1.59634721e+00,\n",
       "           -2.83058405e+00,  2.38457274e+00,  2.31104279e+00,  1.57969737e+00,\n",
       "            1.71988297e+00,  7.99143672e-01, -4.28779459e+00, -1.49072099e+00,\n",
       "           -2.54855919e+00,  2.17254162e+00, -1.59068197e-01, -8.80139589e-01,\n",
       "           -7.14827776e-02,  8.65632296e-03, -1.17861617e+00, -2.93506861e-01,\n",
       "           -3.59516144e-02,  4.93971407e-01, -5.06074369e-01, -1.44177508e+00,\n",
       "           -2.09385204e+00,  2.58792591e+00,  9.19998050e-01,  2.64681768e+00,\n",
       "            2.12276548e-01,  6.08056188e-02, -6.08088613e-01,  1.48125339e+00,\n",
       "            1.30256557e+00, -9.81124341e-01,  1.37281621e+00, -3.89680147e+00,\n",
       "            7.44511843e-01,  3.57167315e+00, -7.63249338e-01,  2.39719772e+00,\n",
       "            9.43527520e-01,  3.31630039e+00,  1.99633503e+00, -6.47061944e-01,\n",
       "            6.11509562e-01,  2.32620096e+00, -2.08588648e+00,  2.71734178e-01,\n",
       "           -7.13891447e-01,  8.54873657e-03,  9.51942325e-01,  1.96052149e-01,\n",
       "            3.27410269e+00,  5.28530359e-01, -1.69658470e+00,  9.22411978e-01,\n",
       "            1.54323733e+00, -3.89937067e+00, -1.33906591e+00,  3.63251209e-01,\n",
       "            2.30311108e+00, -1.14952707e+00, -2.21396232e+00,  1.62235349e-01,\n",
       "           -2.66377807e+00,  1.10911477e+00, -1.78280008e+00,  2.01982439e-01,\n",
       "            2.31819749e-01,  2.05077457e+00, -3.27165127e-02,  6.92593455e-01,\n",
       "           -3.78087312e-01, -1.01039028e+00,  1.61558008e+00, -2.23773837e+00,\n",
       "            1.28045774e+00,  8.60685110e-02, -1.90267110e+00, -1.67353487e+00,\n",
       "            2.80056143e+00,  1.37178075e+00,  8.71363878e-02,  2.43150973e+00,\n",
       "            5.35457373e-01, -4.76304150e+00, -2.06200063e-01,  1.20177433e-01,\n",
       "           -5.76713741e-01,  1.61954796e+00, -8.50207448e-01,  9.03954387e-01,\n",
       "            2.62910533e+00,  1.56147063e-01,  9.37670529e-01,  2.15377188e+00,\n",
       "            1.44607878e+00, -2.38779044e+00,  1.76358211e+00,  1.21621454e+00,\n",
       "           -1.29472351e+00, -1.82188058e+00, -1.15964782e+00,  1.19024539e+00,\n",
       "           -1.86272740e+00,  3.61862898e+00,  1.62420619e+00,  3.54259014e-02,\n",
       "            5.28383434e-01,  9.74538922e-01, -2.13682938e+00,  8.43859792e-01,\n",
       "           -5.01461864e-01,  3.05812383e+00,  1.34364080e+00,  5.39458811e-01,\n",
       "            2.02886963e+00, -1.54815507e+00,  4.15264606e-01, -1.40666485e+00,\n",
       "           -3.01712823e+00,  4.52028573e-01,  7.21094668e-01, -6.09763622e-01,\n",
       "            2.96740472e-01, -7.15194881e-01,  2.24750233e+00, -2.99584031e-01,\n",
       "            4.25230861e-01, -3.20343614e+00,  3.26271033e+00, -1.06121868e-01,\n",
       "           -1.03828394e+00,  2.01235771e+00,  7.79943168e-01,  1.16153085e+00,\n",
       "            1.99974942e+00,  2.38278842e+00,  7.79030621e-01, -3.85052395e+00,\n",
       "           -1.52217305e+00,  1.86382103e+00, -1.78831244e+00,  1.02783239e+00,\n",
       "            1.00529277e+00, -2.25266790e+00, -7.21164882e-01, -5.81745207e-02,\n",
       "            8.97467852e-01,  1.31278265e+00,  1.99536729e+00,  1.09198856e+00,\n",
       "           -8.68109405e-01, -4.28749681e-01, -1.20015812e+00, -4.86263126e-01,\n",
       "           -2.71738672e+00,  4.19943237e+00, -1.07266530e-01,  1.63844562e+00,\n",
       "           -1.13778687e+00, -3.24644506e-01, -2.20826888e+00, -1.67515421e+00,\n",
       "            8.59613895e-01,  4.26026583e-01, -5.75673342e-01,  4.65772152e-01,\n",
       "            1.13850832e-02, -1.06191826e+00, -1.13617957e+00, -7.18962312e-01,\n",
       "            3.44302714e-01, -1.28824472e+00, -2.32789695e-01,  7.36604929e-02,\n",
       "            1.35629725e+00, -1.93316960e+00,  8.03165734e-01,  6.97853923e-01,\n",
       "            2.98730224e-01,  1.60821295e+00, -2.58493853e+00,  9.65370417e-01,\n",
       "            5.02794802e-01,  1.34555495e+00,  2.57546568e+00, -1.40630281e+00,\n",
       "            8.59448135e-01,  3.23166132e-01,  4.50062752e-02,  1.35245359e+00,\n",
       "           -3.92903388e-01,  3.91332567e-01, -1.69607234e+00,  7.10235476e-01,\n",
       "            1.06641364e+00, -1.96038020e+00,  5.17734110e-01,  2.47316194e+00,\n",
       "           -1.90389657e+00, -7.02258587e-01,  3.27441597e+00,  7.96895444e-01,\n",
       "           -4.99746799e-01,  8.47405434e-01, -2.93619633e-01, -2.34267139e+00,\n",
       "            2.72662115e+00, -2.84295797e-01, -2.45224550e-01,  9.02549028e-01,\n",
       "            1.11547136e+00,  1.14233685e+00, -1.12344813e+00,  4.68162358e-01,\n",
       "           -1.49302816e+00,  7.86843061e-01, -7.21295714e-01,  1.51249862e+00,\n",
       "           -1.54429007e+00, -2.84798193e+00, -4.13349581e+00,  2.04400611e+00,\n",
       "            3.02166319e+00,  2.94688129e+00, -7.33603060e-01,  6.50389254e-01,\n",
       "            8.94630969e-01,  2.63780618e+00,  1.97066903e-01,  2.08976448e-01,\n",
       "            8.12320232e-01, -5.03048420e-01,  1.95252848e+00, -9.67642903e-01,\n",
       "           -1.11219597e+00,  5.01162529e+00,  1.53329444e+00, -3.27760863e+00,\n",
       "           -5.12911677e-02, -8.84043276e-02,  4.70839143e-01,  2.57009125e+00,\n",
       "            8.86746764e-01,  9.35844302e-01,  2.11938262e-01,  2.46376529e-01,\n",
       "            2.26991892e+00,  4.59739625e-01,  4.06311542e-01, -5.94419897e-01,\n",
       "            6.03171945e-01, -2.29174662e+00,  1.97653413e+00,  1.74889350e+00,\n",
       "            2.49901390e+00, -1.44275343e+00,  1.88805866e+00, -6.43781185e-01,\n",
       "           -4.80096531e+00,  9.10667598e-01, -2.18171644e+00,  7.29178548e-01,\n",
       "            7.27984548e-01,  4.30567592e-01, -7.21256286e-02,  1.86918283e+00,\n",
       "            1.70347118e+00,  2.63458014e+00,  3.73427808e-01,  8.25763822e-01,\n",
       "            3.80532682e-01,  1.14235926e+00,  1.68368268e+00,  1.23336005e+00,\n",
       "           -1.66452646e+00,  8.68724287e-01, -1.88104540e-01, -6.26185656e-01,\n",
       "            9.00469303e-01, -1.68272829e+00,  9.00546312e-01, -2.08545744e-01,\n",
       "           -1.60233521e+00, -2.76720285e-01,  9.78456736e-01, -1.64104629e+00,\n",
       "           -3.28797579e-01, -1.94975448e+00, -2.73044777e+00,  2.04208598e-01,\n",
       "            3.72693181e-01, -1.86729276e+00,  7.08595097e-01, -2.56884313e+00,\n",
       "           -3.53928566e-01,  1.80848694e+00, -1.31548285e-01,  2.81997538e+00,\n",
       "           -3.77755344e-01,  1.84882879e+00,  1.57129061e+00, -3.05962849e+00,\n",
       "           -9.26609576e-01, -8.03118527e-01, -1.49504161e+00, -9.76777554e-01,\n",
       "            1.30063736e+00, -1.76314032e+00,  3.63307863e-01,  1.30512524e+00,\n",
       "           -1.26784277e+00,  7.36505747e-01, -1.25863481e+00, -3.90104592e-01,\n",
       "            1.56399786e+00, -3.47481370e-01,  8.49211395e-01, -1.68104315e+00,\n",
       "            1.04925478e+00, -1.13901293e+00, -1.25832582e+00, -1.81674957e-02,\n",
       "            5.75494170e-01,  4.48506325e-01, -1.67855871e+00, -2.14621305e+00,\n",
       "           -4.41084051e+00,  1.52774549e+00, -7.62987852e-01, -1.20092487e+00,\n",
       "            1.82463479e+00,  5.65232635e-01,  1.73788071e-01, -6.34627223e-01,\n",
       "            2.15621233e+00,  3.46273804e+00, -3.32729268e+00, -4.68474269e-01,\n",
       "           -1.35377502e+00,  1.84087300e+00,  8.61222386e-01,  2.35472417e+00,\n",
       "            1.55289531e-01,  3.50107729e-01, -2.60781384e+00, -8.32659006e-01,\n",
       "            6.49891019e-01, -1.05429912e+00, -2.06665730e+00,  1.36119819e+00,\n",
       "            1.00671840e+00,  1.21281910e+00,  5.18021822e-01,  5.31414688e-01,\n",
       "            1.17481995e+00, -2.47531557e+00, -2.58752251e+00, -1.07294381e+00,\n",
       "            9.58231866e-01,  8.26509058e-01,  3.81214499e-01,  2.11295533e+00,\n",
       "           -6.63672328e-01, -1.68903112e+00, -4.05894160e-01, -1.30939317e+00,\n",
       "            5.29266596e-01,  6.40769482e-01, -8.35785151e-01, -2.47839975e+00,\n",
       "            6.08339787e-01,  1.71408224e+00,  9.99194443e-01, -7.93684125e-01,\n",
       "           -9.88020062e-01, -6.66241050e-01,  1.56872523e+00, -9.38766599e-01,\n",
       "            1.46066582e+00,  1.55434823e+00,  2.08644271e+00,  1.28145218e+00,\n",
       "           -7.60584891e-01, -2.77461767e+00,  4.88790661e-01,  1.27205968e-01,\n",
       "            1.55165517e+00, -1.45918214e+00, -3.83984017e+00,  4.10391045e+00,\n",
       "           -4.03749275e+00,  1.21222782e+00, -1.14519906e+00, -3.61517429e-01,\n",
       "            2.04285812e+00, -2.51066995e+00,  4.69524413e-01, -2.17872882e+00,\n",
       "            1.85509515e+00, -2.99630046e+00, -2.47822094e+00,  1.50519466e+00,\n",
       "           -1.76048264e-01,  9.67864633e-01, -2.15046501e+00, -2.36370397e+00,\n",
       "           -5.12855589e-01,  8.26321959e-01,  6.31325185e-01, -7.36653984e-01,\n",
       "           -2.58705020e+00, -4.95133668e-01, -2.02112913e-01,  1.39556026e+00,\n",
       "           -2.18456459e+00,  1.74535185e-01,  6.50501609e-01, -2.52734876e+00,\n",
       "            5.81269979e-01,  5.48809350e-01,  1.67394590e+00, -2.76077652e+00,\n",
       "           -2.47289598e-01,  1.02628839e+00,  5.68692446e-01,  5.16560078e-01,\n",
       "           -5.11024296e-01, -7.57659256e-01,  1.78099740e+00,  6.40302062e-01,\n",
       "            9.60794210e-01, -9.24818099e-01, -1.88360429e+00, -1.01870203e+00,\n",
       "           -2.17120552e+00,  1.10313296e-01, -1.07060218e+00,  1.03258348e+00,\n",
       "            7.86367059e-01,  2.30143738e+00, -6.21428192e-01,  8.84860039e-01,\n",
       "            1.16328728e+00,  1.41815245e+00, -1.36217475e+00, -1.58453417e+00,\n",
       "           -2.42262650e+00, -1.33313227e+00, -1.90844619e+00,  5.92865765e-01,\n",
       "            1.18946302e+00,  2.18576884e+00, -1.67618716e+00, -3.23899686e-01,\n",
       "           -2.54633570e+00,  7.27064610e-01,  7.88988233e-01,  1.74683678e+00,\n",
       "            2.51791072e+00,  1.27550483e-01,  5.14834046e-01, -5.42196035e-01,\n",
       "           -3.65619600e-01, -2.71298695e+00,  1.82749629e-02,  1.73451543e+00,\n",
       "            1.40616083e+00,  1.01558018e+00, -2.69883752e+00, -3.15548587e+00,\n",
       "            8.01477313e-01, -6.33706570e-01, -1.74795449e-01, -6.04294062e-01,\n",
       "            9.63481903e-01,  7.83454120e-01,  7.17805564e-01, -2.90181494e+00,\n",
       "           -1.52547288e+00, -3.34319878e+00, -7.21346378e-01, -2.68926311e+00,\n",
       "           -4.00982589e-01, -9.50053871e-01, -9.65634584e-01,  4.67549503e-01,\n",
       "            3.64523381e-02, -1.78077722e+00, -2.22636652e+00,  1.48197007e+00,\n",
       "           -1.66968203e+00, -1.22606862e+00, -8.32655430e-02, -2.52808237e+00,\n",
       "            1.32741332e+00, -2.29651153e-01, -1.87515223e+00], dtype=float32)>\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create variables for fixed effects.\n",
    "floor_weight = tf.Variable(0.)\n",
    "bias = tf.Variable(0.)\n",
    "\n",
    "# Variables for scale parameters.\n",
    "log_radon_scale = tfp.util.TransformedVariable(1., tfb.Exp())\n",
    "county_effect_scale = tfp.util.TransformedVariable(1., tfb.Exp())\n",
    "\n",
    "# Define the probabilistic graphical model as a JointDistribution.\n",
    "@tfd.JointDistributionCoroutineAutoBatched\n",
    "def model():\n",
    "  uranium_weight = yield tfd.Normal(0., scale=1., name='uranium_weight')\n",
    "  county_floor_weight = yield tfd.Normal(\n",
    "      0., scale=1., name='county_floor_weight')\n",
    "  county_effect = yield tfd.Sample(\n",
    "      tfd.Normal(0., scale=county_effect_scale),\n",
    "      sample_shape=[num_counties], name='county_effect')\n",
    "  yield tfd.Normal(\n",
    "      loc=(log_uranium * uranium_weight + floor_of_house* floor_weight\n",
    "\n",
    "           + floor_by_county * county_floor_weight\n",
    "           + tf.gather(county_effect, county, axis=-1)\n",
    "           + bias),\n",
    "      scale=log_radon_scale[..., tf.newaxis],\n",
    "      name='log_radon') \n",
    "\n",
    "# Pin the observed `log_radon` values to model the un-normalized posterior.\n",
    "target_model = model.experimental_pin(log_radon=log_radon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:47:12.425700Z",
     "start_time": "2021-06-24T02:47:12.413202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine the `event_shape` of the posterior, and calculate the size of each\n",
    "# `event_shape` component. These determine the sizes of the components of the\n",
    "# underlying standard Normal distribution, and the dimensions of the blocks in\n",
    "# the blockwise matrix transformation.\n",
    "event_shape = target_model.event_shape_tensor()\n",
    "flat_event_shape = tf.nest.flatten(event_shape)\n",
    "flat_event_size = tf.nest.map_structure(tf.reduce_prod, flat_event_shape)\n",
    "\n",
    "# The `event_space_bijector` maps unconstrained values (in R^n) to the support\n",
    "# of the prior -- we'll need this at the end to constrain Multivariate Normal\n",
    "# samples to the prior's support.\n",
    "event_space_bijector = target_model.experimental_default_event_space_bijector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:47:12.474533Z",
     "start_time": "2021-06-24T02:47:12.469647Z"
    }
   },
   "outputs": [],
   "source": [
    "base_standard_dist = tfd.JointDistributionSequential(\n",
    "      [tfd.Sample(tfd.Normal(0., 1.), s) for s in flat_event_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:47:12.804300Z",
     "start_time": "2021-06-24T02:47:12.792173Z"
    }
   },
   "outputs": [],
   "source": [
    "operators = (\n",
    "    (tf.linalg.LinearOperatorDiag,),  # Variance of uranium weight (scalar).\n",
    "    (tf.linalg.LinearOperatorFullMatrix,  # Covariance between uranium and floor-by-county weights.\n",
    "     tf.linalg.LinearOperatorDiag),  # Variance of floor-by-county weight (scalar).\n",
    "    (None,  # Independence between uranium weight and county effects.\n",
    "     None,  #  Independence between floor-by-county and county effects.\n",
    "     tf.linalg.LinearOperatorDiag)  # Independence among the 85 county effects.\n",
    "    )\n",
    "\n",
    "block_tril_linop = (\n",
    "    tfp.experimental.vi.util.build_trainable_linear_operator_block(\n",
    "        operators, flat_event_size))\n",
    "scale_bijector = tfb.ScaleMatvecLinearOperatorBlock(block_tril_linop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:48:39.920268Z",
     "start_time": "2021-06-24T02:48:39.913336Z"
    }
   },
   "outputs": [],
   "source": [
    "loc_bijector = tfb.JointMap(\n",
    "    tf.nest.map_structure(\n",
    "        lambda s: tfb.Shift(\n",
    "            tf.Variable(tf.random.uniform(\n",
    "                (s,), minval=-2., maxval=2., dtype=tf.float32))),\n",
    "        flat_event_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:48:46.093764Z",
     "start_time": "2021-06-24T02:48:46.089083Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape each component to match the prior, using a nested structure of\n",
    "# `Reshape` bijectors wrapped in `JointMap` to form a multipart bijector.\n",
    "reshape_bijector = tfb.JointMap(\n",
    "    tf.nest.map_structure(tfb.Reshape, flat_event_shape))\n",
    "\n",
    "# Restructure the flat list of components to match the prior's structure\n",
    "unflatten_bijector = tfb.Restructure(\n",
    "        tf.nest.pack_sequence_as(\n",
    "            event_shape, range(len(flat_event_shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:48:51.889236Z",
     "start_time": "2021-06-24T02:48:51.881217Z"
    }
   },
   "outputs": [],
   "source": [
    "surrogate_posterior = tfd.TransformedDistribution(\n",
    "    base_standard_dist,\n",
    "    bijector = tfb.Chain(  # Note that the chained bijectors are applied in reverse order\n",
    "        [\n",
    "         event_space_bijector,  # constrain the surrogate to the support of the prior\n",
    "         unflatten_bijector,  # pack the reshaped components into the `event_shape` structure of the posterior\n",
    "         reshape_bijector,  # reshape the vector-valued components to match the shapes of the posterior components\n",
    "         loc_bijector,  # allow for nonzero mean\n",
    "         scale_bijector  # apply the block matrix transformation to the standard Normal distribution\n",
    "         ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-24T02:49:12.722837Z",
     "start_time": "2021-06-24T02:48:58.658391Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5059: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed Tensor(\"monte_carlo_variational_loss/expectation/JointDistributionCoroutineAutoBatched/unnormalized_log_prob/Const:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n",
      "WARNING:tensorflow:From /Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5059: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed Tensor(\"monte_carlo_variational_loss/expectation/JointDistributionCoroutineAutoBatched/unnormalized_log_prob/Const:0\", shape=(2,), dtype=int32), implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n",
      "/Users/sean00002/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow_probability/python/internal/vectorization_util.py:91: UserWarning: Saw Tensor seed [0 0], implying stateless sampling. Autovectorized functions that use stateless sampling may be quite slow because the current implementation falls back to an explicit loop. This will be fixed in the future. For now, you will likely see better performance from stateful sampling, which you can invoke by passing a Python `int` seed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate Normal surrogate posterior ELBO: -1065.68994140625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=1e-2)\n",
    "@tf.function(jit_compile=True)\n",
    "def fit_vi():\n",
    "  return tfp.vi.fit_surrogate_posterior(\n",
    "      target_model.unnormalized_log_prob,\n",
    "      surrogate_posterior,\n",
    "      optimizer=optimizer,\n",
    "      num_steps=10**4,\n",
    "      sample_size=16,\n",
    "      )\n",
    "mvn_loss = fit_vi()\n",
    "\n",
    "mvn_samples = surrogate_posterior.sample(1000)\n",
    "mvn_final_elbo = tf.reduce_mean(\n",
    "    target_model.unnormalized_log_prob(*mvn_samples)\n",
    "\n",
    "    - surrogate_posterior.log_prob(mvn_samples))\n",
    "\n",
    "print('Multivariate Normal surrogate posterior ELBO: {}'.format(mvn_final_elbo))\n",
    "\n",
    "plt.plot(mvn_loss)\n",
    "plt.xlabel('Training step')\n",
    "_ = plt.ylabel('Loss value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
